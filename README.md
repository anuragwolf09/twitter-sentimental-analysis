NATURAL LANGUAGE PROCESSING PROJECT.

MAJOR PROJECT:
 
TWITTER SENTIMENTAL ANALYSIS:

PROJECT DESCRIPTION:

Given Twitter US Airline Sentiment Dataset, which contains data for over 14000 tweets, your task is to predict the sentiment of the tweet i.e. positive, negative or neutral.

ALGORITHMS AND TOOLS USED:

1.NUMPY
2.PANDAS
3.NATURAL LANGUAGE TOOLKIT (NLTK)
4.COUNT VECTORIZER
5.SKLEARN
6.SUPPORT VECTOR MACHINE
7.MULTINOMIAL NAIVE BAYES
8.RANDOM FOREST

APPROACH:

1.LOAD THE DATA 
2.SETTING UP TRAINING AND TESTING DATA.
3.GETTING THE DATA INTO NLTK SUITABLE FORMAT.
4.DOING DATA CLEANING USING NLTK TOOLS : STOPWORDS , POS TAG , WORDNETLEMMATIZER.
5.AFTER GETTING THE DATA CLEANING , NOW INSTEAD OF USING NLTK INBUILT CLASSIFIER WE CAN SHIFT TO SKLEARN CLASSIFIER BY CONVERTING THE DATA INTO SKLEARN SUITABLE DATA FORM.
THEREFORE USING COUNT VECTORIZER TO GET THE DATA INTO M X N MATRIX FORM.
6.APPLYING DIFFERENT SKLEARN CLASSIFIER:
 
 SUPPORT VECTOR MACHINE
 MULTINOMIAL NAIVE BAYES
 RANDOM FOREST

RESULT:

THE PREDICTIONS WERE TESTED ON CODING NINJAS WEBSITE AS IT WAS A CODING NINJA TASK/ASSIGNEMENT AND THE ACCURACY WERE:

1.MULTINOMIAL NAIVE BAYES: 0.7661

2.SUPPORT VECTOR MACHINE : 0.6358

3.RANDOM FOREST : 0.7661

CONCLUSION:

THEREFORE MULTINOMIAL NAIVE BAYES AND RANDOM FOREST GAVE BETTER ACCURACY. 
FURHTER WE CAN USE NUERAL NETWORKS TO GET BETTER ACCURACY. 


OTHER THAN THAT TWO SMALL PROEJCTS ARE ALSO THERE:

1.NLTKBASICS :

 IN NLTK BASICS PYTHON NOTEBOOK I HAVE WRITTEN SOME OF THE BASIC USE OF NATURAL LANGUAGE TOOLKIT USED IN DATA CLEANING. 

 I HAVE ALSO USED ONE OF THE DATASET OF NLTK CORPUS TO TEST SOME OF THE DATA CLEANING FEATURES PROVIDED BY NLTK.

 DATASET:

 DATASET IS OF 'STATE UNION' WHERE I USED '2006-GWBUSH.TXT' SPEECH. 

 TOOLS AND ALGORITHMS USED:

 1.NLTK.TOKENIZE
 2.NLTK.CORPUS
 3.NLTK.STEM
 4.POS TAG
 5.WORDNETLEMMATIZER
 
2. NLP ON MOVIE REVIEWS DATASET: 

 IN NLP MOVIE REVIEWS DATASET FILE I HAVE USED MOVIE REVIEWS DATASET FROM NLTK CORPUS AND PERFORMED CLASSIFICATION ON IT BY FITRST USING NLTK TOOLKIT TO CLEAN THE DATA   AND THEN COUNT VECTORIZER TO GET THE DATA INTO SKLEARN SUITABLE DATA FORMAT. 

 TOOLS AND ALGORITHMS USED:

 1.NATURAL LANGUAGE TOOL KIT TO CLEAN THE DATA.

 2.COUNT VECTORIZER TO GET THE DATA INTO SKLEARN CLASSIFIER SUITABLE FORM.

 3.USED NLTK INBUILT NAIVE BAYES CLASSIFIER.

 4.USED SKLEARN SUPPORT VECTOR CLASSIFIER.

 RESULT: 

 1.USING NLTK NAIVE BAYES CLASSIFIER : 0.674

 2.USING SKLEARN SUPPORT VECTOR CLASSIFIER : 0.778
